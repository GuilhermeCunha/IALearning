# -*- coding: utf-8 -*-
"""Cópia de MLP-Iris.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bHnHJMTpYCBXeu-XwBG76F6ShRb55May

# O dataset da Iris

![title](iris.png)
"""

# Commented out IPython magic to ensure Python compatibility.
import warnings
warnings.filterwarnings('ignore')
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import numpy as np

import keras

from keras.models import Sequential
from keras.layers import Dense, Activation

import matplotlib.pyplot as plt
# %matplotlib inline

iris = load_iris()
iris.keys()

iris['target_names'] # tipos de iris

len(iris['target'])

iris['feature_names'] # características de iris

print(iris['data'].shape)
iris['data'][:10] #contêm as medidas de cada flor

X, y = iris.data[:, :4], iris.target

x_train, x_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)

x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.5)

print('Shape de x_train', x_train.shape)
print('Shape de x_val', x_val.shape)
print('Shape de x_test', x_test.shape)

print('Shape de y_train', y_train.shape)
print('Shape de y_val', y_val.shape)
print('Shape de y_test', y_test.shape)



y_test

fig, ax = plt.subplots(3, 3, figsize=(15,15))

for i in range(3):
    for j in range(3):
        ax[i,j].scatter(x_train[:, j], x_train[:, i+1], c=y_train, s=60)
        ax[i,j].set_xticks(())
        ax[i,j].set_yticks(())
        
        if i == 2:
            ax[i,j].set_xlabel(iris['feature_names'][j])
        if j == 0:
            ax[i,j].set_ylabel(iris['feature_names'][i + 1])
        if j > i:
            ax[i,j].set_visible(False)

x_train[:, 0]

model = Sequential()

# Layer de tamanho 16 e 4 atributos de flor (sepal x and y, petal x and y)
model.add(Dense(16, input_shape=(4,), activation='tanh'))
model.add(Dense(8, activation="relu"))
# 3 espécies de flor
model.add(Dense(3, activation='softmax'))
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

batch_size = 16
epochs = 200

history = model.fit(x_train, y_train,
                    batch_size=batch_size,
                    epochs=epochs,
                    verbose=1,
                    validation_data=(x_val, y_val))

# Plotando o historico do processo de treinamento
plt.figure(figsize=(20, 5))
plt.plot(history.history['loss'], color='blue')
plt.plot(history.history['val_loss'], color='red')
plt.title('Model loss', fontsize=20)
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['Treinamento', 'Validação'], loc='upper right', fontsize=14)
plt.show()

# 
score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

score

#testing model
x_new = np.array([[5, 2.9, 1, 0.2]])
x_new.shape

prediction = model.predict(x_new)
prediction

iris['target_names'][prediction.argmax()]

